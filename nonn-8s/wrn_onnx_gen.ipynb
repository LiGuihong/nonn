{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlockUnit( nn.Module ):\n",
    "    def __init__( self, ni, no, stride=1, convdim=False, segment=1, i=None, rd_buf=None ):\n",
    "        super( BasicBlockUnit, self ).__init__()\n",
    "        self.segment = segment\n",
    "        self.ni      = ni\n",
    "        self.no      = no\n",
    "        self.id    = i\n",
    "        self.bn0   = nn.BatchNorm2d(int(ni/self.segment))\n",
    "        self.relu0 = nn.ReLU(inplace=True)\n",
    "        self.conv0 = nn.Conv2d( ni, int(no/self.segment), 3, padding=1, stride=stride, bias=False )\n",
    "        self.bn1   = nn.BatchNorm2d(int(no/self.segment))\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d( no, int(no/self.segment), 3, stride=1, padding=1, bias=False )\n",
    "        self.convdim = nn.Conv2d(ni,int(no/self.segment),1,stride=stride, bias=False) if convdim else None\n",
    "        self.rd_buf = rd_buf\n",
    "\n",
    "    def forward( self, x ):\n",
    "        res = x\n",
    "        x = self.bn0  (x)\n",
    "        x = self.relu0(x)\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x1 = self.bn1  (x1)\n",
    "        x1 = self.relu1(x1)\n",
    "\n",
    "        x2 = self.conv1(x1)\n",
    "        if self.convdim is not None:\n",
    "            res = self.convdim(x)\n",
    "        x = x2 + res\n",
    "\n",
    "        return x\n",
    "\n",
    "    def set_param( self, param, prefix ):\n",
    "        i = self.id\n",
    "        if self.convdim is not None:\n",
    "            assert( self.convdim.weight.shape == nn.Parameter(param[ prefix+'.convdim' ]).shape )\n",
    "            self.convdim.weight = nn.Parameter(param[ prefix+'.convdim' ])\n",
    "        assert( self.bn0.weight.shape == nn.Parameter(param[ prefix+'.bn0.weight' ]).shape)\n",
    "        self.bn0.weight   = nn.Parameter(param[ prefix+'.bn0.weight' ])\n",
    "        assert( self.bn0.bias.shape == nn.Parameter(param[ prefix+'.bn0.bias' ]).shape)\n",
    "        self.bn0.bias     = nn.Parameter(param[ prefix+'.bn0.bias' ])\n",
    "        assert( self.conv0.weight.shape == nn.Parameter(param[ prefix+'.conv0' ]).shape)\n",
    "        self.conv0.weight = nn.Parameter(param[ prefix+'.conv0'])\n",
    "        assert( self.bn1.weight.shape == nn.Parameter(param[ prefix+'.bn1.weight' ]).shape)\n",
    "        self.bn1.weight   = nn.Parameter(param[ prefix+'.bn1.weight' ])\n",
    "        assert( self.bn1.bias.shape == nn.Parameter(param[ prefix+'.bn1.bias' ]).shape)\n",
    "        self.bn1.bias     = nn.Parameter(param[ prefix+'.bn1.bias' ])\n",
    "        assert( self.conv1.weight.shape == nn.Parameter(param[ prefix+'.conv1' ]).shape)\n",
    "        self.conv1.weight = nn.Parameter(param[ prefix+'.conv1'])\n",
    "\n",
    "    def set_stats( self, stats, prefix ):\n",
    "        i = self.id\n",
    "        self.bn0.running_mean = nn.Parameter(stats[ prefix+'.bn0.running_mean' ])\n",
    "        self.bn0.running_var = nn.Parameter(stats[ prefix+'.bn0.running_var' ])\n",
    "        self.bn1.running_mean = nn.Parameter(stats[ prefix+'.bn1.running_mean' ])\n",
    "        self.bn1.running_var = nn.Parameter(stats[ prefix+'.bn1.running_var' ])\n",
    "\n",
    "    def set_requires_grad( self, val ):\n",
    "        for para in self.parameters():\n",
    "            para.requires_grad = val\n",
    "\n",
    "\n",
    "def AvgPool2d_in_conv( n, kernel_size ):\n",
    "    avg = nn.Conv2d( n, n, kernel_size, bias=False)\n",
    "    avg_weight = torch.zeros_like(avg.weight)\n",
    "    for i in range(n):\n",
    "        avg_weight[i][i] = torch.ones_like(avg.weight[0][0])\n",
    "    avg.weight = nn.Parameter(avg_weight)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Group(nn.Module):\n",
    "    def __init__( self, ni, no, n, stride=1, segment=1, id=None ):\n",
    "        super( Group, self ).__init__()\n",
    "        self.blocks = []\n",
    "        self.blocks.append( BasicBlockUnit(ni,no,stride,convdim=True,segment=segment,i=id) )\n",
    "        for _ in range(1,n):\n",
    "            self.blocks.append( BasicBlockUnit(no,no,segment=segment,i=id) )\n",
    "    def forward( self, x ):\n",
    "        for b in self.blocks:\n",
    "            x = b.forward(x)\n",
    "        return x\n",
    "    def set_param( self, param, prefix ):\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            b.set_param( param, prefix + '.block' + str(i) )\n",
    "    def set_stats( self, stats, prefix ):\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            b.set_stats( stats, prefix + '.block' + str(i) )\n",
    "\n",
    "    def eval( self ):\n",
    "        for b in self.blocks:\n",
    "            b.eval()\n",
    "        return self.train(False)\n",
    "\n",
    "    def set_requires_grad( self, val ):\n",
    "        for b in self.blocks:\n",
    "            b.set_requires_grad(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRN_extract(nn.Module):\n",
    "    def __init__(self, n=2, num_classes=10, batch_size=1, no_avgpool=True, weights=None, stats=None, widths=None, segment=1, reduce_ip='127.0.0.1', reduce_port=None, id=0, id_stu=0, students=None):\n",
    "\n",
    "        super(WRN_extract,self).__init__()\n",
    "        self.id = id\n",
    "        self.batch_size = batch_size\n",
    "        self.segment = segment\n",
    "        self.id_stu  = id_stu\n",
    "\n",
    "        self.conv0 = nn.Conv2d(3,int(16/segment),3, padding=1, bias=False)\n",
    "        self.groups = []\n",
    "        self.g0 = Group(16, int(widths[0]), n=n, segment=segment, id=id)\n",
    "        self.g1 = Group( int(widths[0]), no=int(widths[1]), n=n, stride=2 )\n",
    "        self.g2 = Group( int(widths[1]), no=int(widths[2]), n=n, stride=2 )\n",
    "        self.conv_g2_dimComm = nn.Conv2d( int(widths[2]), int(widths[3]), 1, bias=False)\n",
    "\n",
    "        assert(id_stu<students)\n",
    "        if students == 8: \n",
    "            g0index = chr( ord('a')+int(id_stu/2) )\n",
    "            gindex  = chr( ord('a')+id_stu )\n",
    "#             print(\"%d:(%c,%c)\"%(id_stu,g0index,gindex))\n",
    "            self.groups_info = []\n",
    "            self.groups_info.append(('group0'+g0index, self.g0))\n",
    "            self.groups_info.append(('group1'+gindex,  self.g1))\n",
    "            self.groups_info.append(('group2'+gindex,  self.g2))\n",
    "        elif students == 2: \n",
    "            gindex = chr( ord('a')+id_stu )\n",
    "            self.groups_info = []\n",
    "            self.groups_info.append(('group0',self.g0))\n",
    "            self.groups_info.append(('group1'+gindex,self.g1))\n",
    "            self.groups_info.append(('group2'+gindex,self.g2))\n",
    "\n",
    "        if weights is not None:\n",
    "            self.load_weight(weights, prefix='student.')\n",
    "\n",
    "        if stats is not None:\n",
    "            self.load_stats(stats, prefix='student.')\n",
    "\n",
    "    def __del__(self):\n",
    "        if hasattr( self, 'c' ):\n",
    "            print(\"Close the reduce port\")\n",
    "            self.c.close()\n",
    "\n",
    "    def load_weight( self, param, prefix=\"\" ):\n",
    "        assert( self.conv0.weight.shape == param[prefix+'conv0'].shape)\n",
    "        self.conv0.weight = nn.Parameter(param[prefix+'conv0'])\n",
    "        g0index = chr( ord('a')+self.id_stu )\n",
    "        assert( self.conv_g2_dimComm.weight.shape == param[prefix+'conv_g2'+g0index+'_dimComm'].shape)\n",
    "        self.conv_g2_dimComm.weight = nn.Parameter(param[prefix+'conv_g2'+g0index+'_dimComm'])\n",
    "        for sub_prefix, g in self.groups_info:\n",
    "            g.set_param( param, prefix+sub_prefix )\n",
    "\n",
    "    def load_stats( self, stats, prefix=\"\" ):\n",
    "        for sub_prefix, g in self.groups_info:\n",
    "            g.set_stats( stats, prefix+sub_prefix )\n",
    "\n",
    "    def forward( self, x ):\n",
    "\n",
    "        x = self.conv0(x)\n",
    "        x = self.g0.forward(x)\n",
    "        x = self.g1.forward(x)\n",
    "        x = self.g2.forward(x)\n",
    "        x = self.conv_g2_dimComm(x)\n",
    "        return x\n",
    "\n",
    "    def set_requires_grad( self, val ):\n",
    "        for g in [self.g0, self.g1, self.g2]:\n",
    "            g.set_requires_grad(val)\n",
    "        for para in self.parameters():\n",
    "            para.requires_grad = val\n",
    "        return\n",
    "\n",
    "    def eval( self ):\n",
    "        for g in [self.g0, self.g1, self.g2]:\n",
    "            g.eval()\n",
    "        return self.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRN_fc(nn.Module):\n",
    "\n",
    "    def __init__(self, n=6, num_classes=10, batch_size=1, no_avgpool=True, weights=None, stats=None, widths=torch.Tensor([16,32,64]).mul(4), students=None):\n",
    "        super(WRN_fc,self).__init__()\n",
    "\n",
    "        if students == 2:\n",
    "            widths = torch.Tensor([32, 64, 64, 87, 87, 34, 46]).int()\n",
    "        elif students == 8:\n",
    "            widths = torch.Tensor([32, 64, 64, 87, 87, 34*4, 46*4]).int()\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        self.width    = int(widths[5]+widths[6])\n",
    "        self.n = n\n",
    "        self.batch_size = batch_size\n",
    "        self.fc       = nn.Linear( self.width, num_classes )\n",
    "        self.bn       = nn.BatchNorm2d(self.width)\n",
    "        self.relu     = nn.ReLU(inplace=True)\n",
    "\n",
    "        if no_avgpool:\n",
    "            self.avg_pool = AvgPool2d_in_conv(int(widths[5]+widths[6]),8)\n",
    "        else:\n",
    "            self.avg_pool = nn.AvgPool2d(8,1,0)\n",
    "\n",
    "\n",
    "\n",
    "        if weights is not None:\n",
    "            self.load_weight(weights, prefix='student.')\n",
    "\n",
    "        if stats is not None:\n",
    "            self.load_stats(stats, prefix='student.')\n",
    "\n",
    "    def load_weight( self, param, prefix ):\n",
    "        self.fc.weight = nn.Parameter(param[prefix+'fc.weight'])\n",
    "        self.fc.bias   = nn.Parameter(param[prefix+'fc.bias'])\n",
    "        assert( self.bn.weight.shape == param[prefix+'bn.weight'].shape)\n",
    "        self.bn.weight = nn.Parameter(param[prefix+'bn.weight'])\n",
    "        assert( self.bn.bias.shape == param[prefix+'bn.bias'].shape)\n",
    "        self.bn.bias   = nn.Parameter(param[prefix+'bn.bias'])\n",
    "\n",
    "    def load_stats( self, stats, prefix ):\n",
    "        assert( self.bn.running_mean.shape == stats[prefix+'bn.running_mean'].shape)\n",
    "        self.bn.running_mean = nn.Parameter(stats[prefix+'bn.running_mean'])\n",
    "        assert( self.bn.running_var.shape == stats[prefix+'bn.running_var'].shape)\n",
    "        self.bn.running_var = nn.Parameter(stats[prefix+'bn.running_var'])\n",
    "        return\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc(x.view(self.batch_size,self.width))\n",
    "        return x\n",
    "\n",
    "    def set_requires_grad( self, val ):\n",
    "        for para in self.parameters():\n",
    "            para.requires_grad = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WRN(nn.Module):\n",
    "\n",
    "    def __init__(self, n=6, num_classes=10, batch_size=1, no_avgpool=True, weights=None, stats=None, widths=torch.Tensor([16,32,64]).mul(4), students=None):\n",
    "        super(WRN,self).__init__()\n",
    "        self.extr = []\n",
    "        if students == 2:\n",
    "            self.extr.append( WRN_extract( weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 34]), id_stu=0, students=students))\n",
    "            self.extr.append( WRN_extract( weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 46]), id_stu=1, students=students))\n",
    "        elif students == 8:\n",
    "            self.extr.append( WRN_extract( weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 34]), id_stu=0, students=students))\n",
    "            self.extr.append( WRN_extract( weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 46]), id_stu=1, students=students))\n",
    "            self.extr.append( WRN_extract( weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 34]), id_stu=2, students=students))\n",
    "            self.extr.append( WRN_extract( weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 46]), id_stu=3, students=students))\n",
    "            self.extr.append( WRN_extract( weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 34]), id_stu=4, students=students))\n",
    "            self.extr.append( WRN_extract( weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 46]), id_stu=5, students=students))\n",
    "            self.extr.append( WRN_extract( weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 34]), id_stu=6, students=students))\n",
    "            self.extr.append( WRN_extract( weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 46]), id_stu=7, students=students))\n",
    "        self.fc    = WRN_fc(      weights=param['params'], stats=param['stats'], students=students )\n",
    "\n",
    "    def forward(self, x):\n",
    "        partial_x = []\n",
    "        for extr in self.extr:\n",
    "            partial_x.append(extr(x))\n",
    "        x = torch.cat(tuple(partial_x), dim=1)\n",
    "#         for i,xx in enumerate(partial_x):\n",
    "#             print(\"%d:\"%i, xx.shape, xx[0][0][0])\n",
    "        return self.fc(x)\n",
    "\n",
    "    def eval( self ):\n",
    "        self.fc.eval()\n",
    "        for m in self.extr:\n",
    "            m.eval()\n",
    "\n",
    "    def set_requires_grad( self, val ):\n",
    "        self.fc.set_requires_grad(val)\n",
    "        for m in self.extr:\n",
    "            m.set_requires_grad(val)\n",
    "        for para in self.parameters():\n",
    "            para.requires_grad = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 1\n",
    "    pt7_path   = None\n",
    "    cifar      = \"..\"\n",
    "    config     = 'config.xml'\n",
    "    dataset    = 'CIFAR10'\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model generation\n",
    "## 2 students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "verbose = False\n",
    "args.output = 'wrn_2s_'\n",
    "args.pt7_path = \"/home/chingyi/Downloads/NoNN_fixFLOPS_RPI_models/logs/ST_swrn_v6a_WRN40-4_b=10K_a=0.9_norm_2S_fixFLOPS_run4/model.pt7\"\n",
    "param = torch.load(  args.pt7_path, map_location='cpu' )\n",
    "extr = []\n",
    "n_students = 2\n",
    "for i in range(int(n_students/2)):\n",
    "    extr.append( WRN_extract( batch_size=args.batch_size, weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 34]), id_stu=2*i+0, students=n_students))\n",
    "    extr.append( WRN_extract( batch_size=args.batch_size, weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 46]), id_stu=2*i+1, students=n_students))\n",
    "fc = WRN_fc(                  batch_size=args.batch_size, weights=param['params'], stats=param['stats'], students=n_students )\n",
    "\n",
    "# Load parameters    \n",
    "param = torch.load( args.pt7_path, map_location='cpu' )\n",
    "for m in extr+[fc]:\n",
    "    m.set_requires_grad(False)\n",
    "    m.eval()\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.onnx\n",
    "\n",
    "for i, m in enumerate(extr):\n",
    "    dummy_input = Variable(torch.randn(args.batch_size, 3, 32, 32))\n",
    "    torch.onnx.export(m, dummy_input, args.output+\"_g\"+str(i)+\".onnx\", verbose=verbose)\n",
    "\n",
    "dummy_input = Variable(torch.randn(args.batch_size, 80, 8, 8))\n",
    "torch.onnx.export(fc, dummy_input, args.output+\"_fc.onnx\", verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "args.output = 'wrn_8s_'\n",
    "args.pt7_path = \"/home/chingyi/Downloads/NoNN_fixFLOPS_RPI_models/logs/ST_swrn_v6n_quadruple6a_WRN40-4_b=10K_a=0.9_norm_8S_run5_fixFLOPS/model.pt7\"\n",
    "param = torch.load(  args.pt7_path, map_location='cpu' )\n",
    "extr = []\n",
    "n_students = 8\n",
    "for i in range(int(n_students/2)):\n",
    "    extr.append( WRN_extract( batch_size=args.batch_size, weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 34]), id_stu=2*i+0, students=n_students))\n",
    "    extr.append( WRN_extract( batch_size=args.batch_size, weights=param['params'], stats=param['stats'], widths=torch.Tensor([32, 64, 87, 46]), id_stu=2*i+1, students=n_students))\n",
    "fc = WRN_fc(                  batch_size=args.batch_size, weights=param['params'], stats=param['stats'], students=n_students )\n",
    "\n",
    "# Load parameters    \n",
    "param = torch.load( args.pt7_path, map_location='cpu' )\n",
    "for m in extr+[fc]:\n",
    "    m.set_requires_grad(False)\n",
    "    m.eval()\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.onnx\n",
    "\n",
    "for i, m in enumerate(extr):\n",
    "    dummy_input = Variable(torch.randn(args.batch_size, 3, 32, 32))\n",
    "    torch.onnx.export(m, dummy_input, args.output+\"_8s_g\"+str(i)+\".onnx\", verbose=verbose)\n",
    "\n",
    "dummy_input = Variable(torch.randn(args.batch_size, 320, 8, 8))\n",
    "torch.onnx.export(fc, dummy_input, args.output+\"_fc.onnx\", verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "## Argument Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size = 1\n",
    "    pt7_path   = \"/home/chingyi/Downloads/NoNN_fixFLOPS_RPI_models/logs/ST_swrn_v6a_WRN40-4_b=10K_a=0.9_norm_2S_fixFLOPS_run4/model.pt7\"\n",
    "#     pt7_path   = \" /home/chingyi/Downloads/NoNN_fixFLOPS_RPI_models/logs/ST_swrn_v6a_WRN40-4_b=10K_a=0.9_norm_2S_fixFLOPS_run4/model.pt7\"\n",
    "    cifar      = \"..\"\n",
    "    config     = 'config.xml'\n",
    "    dataset    = 'CIFAR10'\n",
    "    to_onnx    = False\n",
    "    output     = 'wrn'\n",
    "    inference  = True\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset( dataset_name ):\n",
    "    if dataset_name == \"CIFAR10\":\n",
    "        import torchvision\n",
    "        dataset = torchvision.datasets.CIFAR10( args.cifar, train=False, download=True)\n",
    "    return dataset\n",
    "\n",
    "def normalize_unsqueeze( img, mean, std ):\n",
    "    import torch\n",
    "    import torchvision\n",
    "    to_tensor = torchvision.transforms.ToTensor()\n",
    "    img_tensor = to_tensor(img).transpose(0,2)\n",
    "    img_tensor = img_tensor-(torch.Tensor(mean)/256)\n",
    "    img_tensor = img_tensor/(torch.Tensor( std)/256)\n",
    "    img_tensor = img_tensor.transpose(0,2)\n",
    "    return img_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "1 / 1\n",
      "2 / 2\n",
      "3 / 3\n",
      "4 / 4\n",
      "5 / 5\n",
      "6 / 6\n",
      "7 / 7\n",
      "8 / 8\n",
      "9 / 9\n",
      "10 / 10\n",
      "11 / 11\n",
      "12 / 12\n",
      "13 / 13\n",
      "14 / 14\n",
      "15 / 15\n",
      "15 / 16\n",
      "16 / 17\n",
      "17 / 18\n",
      "18 / 19\n",
      "19 / 20\n",
      "20 / 21\n",
      "21 / 22\n",
      "22 / 23\n",
      "23 / 24\n",
      "24 / 25\n",
      "25 / 26\n",
      "26 / 27\n",
      "27 / 28\n",
      "28 / 29\n",
      "29 / 30\n",
      "30 / 31\n",
      "31 / 32\n",
      "32 / 33\n",
      "32 / 34\n",
      "33 / 35\n",
      "34 / 36\n",
      "35 / 37\n",
      "35 / 38\n",
      "36 / 39\n",
      "37 / 40\n",
      "38 / 41\n",
      "39 / 42\n",
      "40 / 43\n",
      "41 / 44\n",
      "42 / 45\n",
      "43 / 46\n",
      "44 / 47\n",
      "45 / 48\n",
      "46 / 49\n",
      "47 / 50\n",
      "48 / 51\n",
      "49 / 52\n",
      "49 / 53\n",
      "50 / 54\n",
      "51 / 55\n",
      "52 / 56\n",
      "53 / 57\n",
      "54 / 58\n",
      "54 / 59\n",
      "54 / 60\n",
      "55 / 61\n",
      "55 / 62\n",
      "56 / 63\n",
      "57 / 64\n",
      "58 / 65\n",
      "59 / 66\n",
      "60 / 67\n",
      "61 / 68\n",
      "62 / 69\n",
      "63 / 70\n",
      "64 / 71\n",
      "65 / 72\n",
      "66 / 73\n",
      "67 / 74\n",
      "68 / 75\n",
      "69 / 76\n",
      "70 / 77\n",
      "71 / 78\n",
      "72 / 79\n",
      "73 / 80\n",
      "74 / 81\n",
      "75 / 82\n",
      "76 / 83\n",
      "77 / 84\n",
      "78 / 85\n",
      "79 / 86\n",
      "80 / 87\n",
      "81 / 88\n",
      "82 / 89\n",
      "83 / 90\n",
      "84 / 91\n",
      "85 / 92\n",
      "86 / 93\n",
      "87 / 94\n",
      "88 / 95\n",
      "89 / 96\n",
      "90 / 97\n",
      "91 / 98\n",
      "92 / 99\n",
      "93 / 100\n",
      "94 / 101\n",
      "95 / 102\n",
      "96 / 103\n",
      "97 / 104\n",
      "98 / 105\n",
      "99 / 106\n",
      "100 / 107\n",
      "101 / 108\n",
      "102 / 109\n",
      "103 / 110\n",
      "104 / 111\n",
      "105 / 112\n",
      "106 / 113\n",
      "107 / 114\n",
      "108 / 115\n",
      "109 / 116\n",
      "110 / 117\n",
      "111 / 118\n",
      "111 / 119\n",
      "112 / 120\n",
      "113 / 121\n",
      "114 / 122\n",
      "115 / 123\n",
      "116 / 124\n",
      "117 / 125\n",
      "118 / 126\n",
      "119 / 127\n",
      "120 / 128\n",
      "120 / 129\n",
      "121 / 130\n",
      "122 / 131\n",
      "123 / 132\n",
      "124 / 133\n",
      "125 / 134\n",
      "126 / 135\n",
      "127 / 136\n",
      "128 / 137\n",
      "129 / 138\n",
      "130 / 139\n",
      "131 / 140\n",
      "132 / 141\n",
      "133 / 142\n",
      "134 / 143\n",
      "135 / 144\n",
      "136 / 145\n",
      "137 / 146\n",
      "138 / 147\n",
      "138 / 148\n",
      "139 / 149\n",
      "140 / 150\n",
      "141 / 151\n",
      "142 / 152\n",
      "143 / 153\n",
      "144 / 154\n",
      "145 / 155\n",
      "146 / 156\n",
      "147 / 157\n",
      "148 / 158\n",
      "148 / 159\n",
      "149 / 160\n",
      "150 / 161\n",
      "151 / 162\n",
      "152 / 163\n",
      "153 / 164\n",
      "154 / 165\n",
      "155 / 166\n",
      "156 / 167\n",
      "157 / 168\n",
      "158 / 169\n",
      "159 / 170\n",
      "160 / 171\n",
      "161 / 172\n",
      "162 / 173\n",
      "163 / 174\n",
      "164 / 175\n",
      "165 / 176\n",
      "166 / 177\n",
      "167 / 178\n",
      "167 / 179\n",
      "168 / 180\n",
      "169 / 181\n",
      "170 / 182\n",
      "171 / 183\n",
      "172 / 184\n",
      "173 / 185\n",
      "174 / 186\n",
      "175 / 187\n",
      "176 / 188\n",
      "177 / 189\n",
      "178 / 190\n",
      "179 / 191\n",
      "180 / 192\n",
      "181 / 193\n",
      "182 / 194\n",
      "183 / 195\n",
      "184 / 196\n",
      "185 / 197\n",
      "186 / 198\n",
      "187 / 199\n",
      "188 / 200\n",
      "189 / 201\n",
      "190 / 202\n",
      "191 / 203\n",
      "192 / 204\n",
      "193 / 205\n",
      "194 / 206\n",
      "195 / 207\n",
      "196 / 208\n",
      "197 / 209\n",
      "198 / 210\n",
      "199 / 211\n",
      "200 / 212\n",
      "201 / 213\n",
      "201 / 214\n",
      "202 / 215\n",
      "203 / 216\n",
      "204 / 217\n",
      "205 / 218\n",
      "206 / 219\n",
      "207 / 220\n",
      "208 / 221\n",
      "208 / 222\n",
      "209 / 223\n",
      "210 / 224\n",
      "211 / 225\n",
      "212 / 226\n",
      "212 / 227\n",
      "213 / 228\n",
      "213 / 229\n",
      "214 / 230\n",
      "215 / 231\n",
      "216 / 232\n",
      "216 / 233\n",
      "217 / 234\n",
      "218 / 235\n",
      "219 / 236\n",
      "220 / 237\n",
      "221 / 238\n",
      "222 / 239\n",
      "223 / 240\n",
      "224 / 241\n",
      "225 / 242\n",
      "226 / 243\n",
      "227 / 244\n",
      "228 / 245\n",
      "229 / 246\n",
      "230 / 247\n",
      "231 / 248\n",
      "232 / 249\n",
      "233 / 250\n",
      "234 / 251\n",
      "235 / 252\n",
      "236 / 253\n",
      "237 / 254\n",
      "238 / 255\n",
      "239 / 256\n",
      "240 / 257\n",
      "241 / 258\n",
      "241 / 259\n",
      "242 / 260\n",
      "243 / 261\n",
      "244 / 262\n",
      "245 / 263\n",
      "245 / 264\n",
      "245 / 265\n",
      "246 / 266\n",
      "247 / 267\n",
      "248 / 268\n",
      "249 / 269\n",
      "250 / 270\n",
      "251 / 271\n",
      "252 / 272\n",
      "253 / 273\n",
      "254 / 274\n",
      "255 / 275\n",
      "255 / 276\n",
      "256 / 277\n",
      "257 / 278\n",
      "258 / 279\n",
      "259 / 280\n",
      "260 / 281\n",
      "261 / 282\n",
      "262 / 283\n",
      "263 / 284\n",
      "264 / 285\n",
      "265 / 286\n",
      "266 / 287\n",
      "266 / 288\n",
      "267 / 289\n",
      "268 / 290\n",
      "269 / 291\n",
      "270 / 292\n",
      "271 / 293\n",
      "271 / 294\n",
      "272 / 295\n",
      "273 / 296\n",
      "274 / 297\n",
      "275 / 298\n",
      "276 / 299\n",
      "277 / 300\n",
      "278 / 301\n",
      "279 / 302\n",
      "280 / 303\n",
      "281 / 304\n",
      "282 / 305\n",
      "283 / 306\n",
      "284 / 307\n",
      "285 / 308\n",
      "285 / 309\n",
      "286 / 310\n",
      "287 / 311\n",
      "288 / 312\n",
      "289 / 313\n",
      "290 / 314\n",
      "291 / 315\n",
      "292 / 316\n",
      "293 / 317\n",
      "294 / 318\n",
      "295 / 319\n",
      "296 / 320\n",
      "297 / 321\n",
      "298 / 322\n",
      "299 / 323\n",
      "300 / 324\n",
      "301 / 325\n",
      "302 / 326\n",
      "303 / 327\n",
      "304 / 328\n",
      "305 / 329\n",
      "306 / 330\n",
      "307 / 331\n",
      "308 / 332\n",
      "309 / 333\n",
      "310 / 334\n",
      "311 / 335\n",
      "312 / 336\n",
      "313 / 337\n",
      "314 / 338\n",
      "315 / 339\n",
      "316 / 340\n",
      "317 / 341\n",
      "318 / 342\n",
      "319 / 343\n",
      "320 / 344\n",
      "321 / 345\n",
      "322 / 346\n",
      "323 / 347\n",
      "324 / 348\n",
      "325 / 349\n",
      "326 / 350\n",
      "327 / 351\n",
      "328 / 352\n",
      "329 / 353\n",
      "330 / 354\n",
      "331 / 355\n",
      "332 / 356\n",
      "333 / 357\n",
      "334 / 358\n",
      "335 / 359\n",
      "336 / 360\n",
      "337 / 361\n",
      "338 / 362\n",
      "339 / 363\n",
      "340 / 364\n",
      "341 / 365\n",
      "342 / 366\n",
      "343 / 367\n",
      "344 / 368\n",
      "345 / 369\n",
      "346 / 370\n",
      "347 / 371\n",
      "348 / 372\n",
      "349 / 373\n",
      "350 / 374\n",
      "351 / 375\n",
      "352 / 376\n",
      "353 / 377\n",
      "354 / 378\n",
      "354 / 379\n",
      "355 / 380\n",
      "356 / 381\n",
      "357 / 382\n",
      "358 / 383\n",
      "359 / 384\n",
      "359 / 385\n",
      "360 / 386\n",
      "361 / 387\n",
      "362 / 388\n",
      "363 / 389\n",
      "364 / 390\n",
      "365 / 391\n",
      "366 / 392\n",
      "367 / 393\n",
      "368 / 394\n",
      "368 / 395\n",
      "369 / 396\n",
      "370 / 397\n",
      "371 / 398\n",
      "372 / 399\n",
      "373 / 400\n",
      "374 / 401\n",
      "375 / 402\n",
      "376 / 403\n",
      "377 / 404\n",
      "378 / 405\n",
      "379 / 406\n",
      "380 / 407\n",
      "381 / 408\n",
      "382 / 409\n",
      "383 / 410\n",
      "384 / 411\n",
      "384 / 412\n",
      "385 / 413\n",
      "386 / 414\n",
      "387 / 415\n",
      "388 / 416\n",
      "389 / 417\n",
      "390 / 418\n",
      "391 / 419\n",
      "392 / 420\n",
      "393 / 421\n",
      "394 / 422\n",
      "395 / 423\n",
      "396 / 424\n",
      "397 / 425\n",
      "398 / 426\n",
      "398 / 427\n",
      "399 / 428\n",
      "400 / 429\n",
      "401 / 430\n",
      "402 / 431\n",
      "403 / 432\n",
      "404 / 433\n",
      "405 / 434\n",
      "406 / 435\n",
      "407 / 436\n",
      "408 / 437\n",
      "409 / 438\n",
      "410 / 439\n",
      "410 / 440\n",
      "411 / 441\n",
      "412 / 442\n",
      "413 / 443\n",
      "414 / 444\n",
      "415 / 445\n",
      "416 / 446\n",
      "417 / 447\n",
      "418 / 448\n",
      "419 / 449\n",
      "419 / 450\n",
      "420 / 451\n",
      "421 / 452\n",
      "422 / 453\n",
      "423 / 454\n",
      "424 / 455\n",
      "425 / 456\n",
      "425 / 457\n",
      "426 / 458\n",
      "427 / 459\n",
      "428 / 460\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-ebf3442ca1f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnormed\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mnormalize_unsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m125.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m123.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m113.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m63\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m62.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m66.7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mscrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtotal\u001b[0m   \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-c63e92f09792>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mpartial_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mextr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mpartial_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         for i,xx in enumerate(partial_x):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-32b0b111c2d4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_g2_dimComm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-989c4a8040a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_param\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b16d85b8edd3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args.pt7_path = \"/home/chingyi/Downloads/NoNN_fixFLOPS_RPI_models/logs/ST_swrn_v6a_WRN40-4_b=10K_a=0.9_norm_2S_fixFLOPS_run4/model.pt7\"\n",
    "param = torch.load(  args.pt7_path, map_location='cpu' )\n",
    "model = WRN( weights=param['params'], stats=param['stats'], students=2 )\n",
    "model.set_requires_grad(False)\n",
    "model.eval()\n",
    "\n",
    "correct, total = 0, 0\n",
    "cifar = get_dataset( args.dataset )\n",
    "for batch_idx, (inputs, targets) in enumerate(cifar):\n",
    "    normed    = normalize_unsqueeze(inputs, [125.3, 123.0, 113.9], [63, 62.1, 66.7])\n",
    "    scrs = model(normed)\n",
    "    predicted = np.argmax(scrs.numpy())\n",
    "    total   += 1\n",
    "    correct += predicted==targets\n",
    "    print(correct,'/',total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "1 / 1\n",
      "2 / 2\n",
      "3 / 3\n",
      "4 / 4\n",
      "5 / 5\n",
      "6 / 6\n",
      "7 / 7\n",
      "8 / 8\n",
      "9 / 9\n",
      "10 / 10\n",
      "11 / 11\n",
      "12 / 12\n",
      "13 / 13\n",
      "14 / 14\n",
      "15 / 15\n",
      "16 / 16\n",
      "17 / 17\n",
      "18 / 18\n",
      "19 / 19\n",
      "20 / 20\n",
      "21 / 21\n",
      "22 / 22\n",
      "23 / 23\n",
      "24 / 24\n",
      "25 / 25\n",
      "26 / 26\n",
      "27 / 27\n",
      "28 / 28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-cac8e0e8bbf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnormed\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mnormalize_unsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m125.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m123.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m113.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m63\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m62.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m66.7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mscrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtotal\u001b[0m   \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-c63e92f09792>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mpartial_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mextr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mpartial_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         for i,xx in enumerate(partial_x):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-32b0b111c2d4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-989c4a8040a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_param\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b16d85b8edd3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args.pt7_path = \"/home/chingyi/Downloads/NoNN_fixFLOPS_RPI_models/logs/ST_swrn_v6n_quadruple6a_WRN40-4_b=10K_a=0.9_norm_8S_run5_fixFLOPS/model.pt7\"\n",
    "param = torch.load(  args.pt7_path, map_location='cpu' )\n",
    "model = WRN( weights=param['params'], stats=param['stats'], students=8 )\n",
    "model.set_requires_grad(False)\n",
    "model.eval()\n",
    "\n",
    "correct, total = 0, 0\n",
    "cifar = get_dataset( args.dataset )\n",
    "for batch_idx, (inputs, targets) in enumerate(cifar):\n",
    "    normed    = normalize_unsqueeze(inputs, [125.3, 123.0, 113.9], [63, 62.1, 66.7])\n",
    "    scrs = model(normed)\n",
    "    predicted = np.argmax(scrs.numpy())\n",
    "    total   += 1\n",
    "    correct += predicted==targets\n",
    "    print(correct,'/',total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
